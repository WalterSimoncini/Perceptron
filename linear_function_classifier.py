import sys
import csv
import time 
import random

line_separator = "\n------------------------------------------------------------------\n"
learning_constant = 0.1

verbose = True

# To suppress the verbose output use "n" as a command line argument
if len(sys.argv) >= 2:
    verbose = sys.argv[1] != "n"

# Load a csv file in the format x, y, z where z is an integer with the 
# value 0 or 1 that defines whether the point with the coordinates (x, y)
# is above or below the line
def load_csv_data(file_name):
    targets = []
    inputs = []

    with open(file_name, 'rb') as csv_file:
        csv_data = csv.reader(csv_file, delimiter=',')

        for row in csv_data:
            targets.append(int(row[2]))

            # The values of each input array correspond to x, y and to the bias input which is always one
            inputs.append([int(row[0]), int(row[1]), 1])
    
    return (targets, inputs)

# Load the training data set
training_csv = load_csv_data('training.csv')
targets = training_csv[0]
inputs = training_csv[1]

# Initialize the weights with random values
weights = [random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)]
sum_error = 1000

# This function implements the behavior of the sign function:
# if the input value is higher than 0 it will return 1 and 0 
# otherwise.
def activation_function (value):
        if value > 0:
            return 1
        else:
            return 0

if verbose:
    print("Random weights: " + str(weights) + line_separator)

epoch = 1

# Train the network until we reach a total error of 0 which means
# that the perceptron can predict 100% of the training data set
while sum_error > 0:
    sum_error = 0.0

    for i in range(0, len(targets)):
        t = targets[i]

        # Calculate the sum of the network inputs
        output = inputs[i][0] * weights[0] + inputs[i][1] * weights[1] + inputs[i][2] * weights[2]

        # Calculate the output of the network
        activation = activation_function(output)

        # Calculate the error generated by the network, calculated as the difference between
        # the target and the output generated by the network
        error = t - activation

        sum_error += abs(error)

        # Calculate the deltas added to the weights of the input nodes
        for j in range(0, len(weights)):
            delta = learning_constant * error * inputs[i][j]
            weights[j] += delta

        if verbose:
            print("Target: " + str(t) + " - Ouput: " + str(activation) + " - " + str(weights))
    
    if verbose:
        print("\nEpoch " + str(epoch) + " with error sum: " + str(sum_error) + line_separator)

    # If the verbose mode is active pause 1 second between each epoch to let
    # the user see the perceptron's progress
    if verbose:
        time.sleep(1)
    
    epoch += 1

if verbose:
    print("Training complete - Performing validation... " + line_separator)

# Load the validation data set
validation_csv = load_csv_data('validation.csv')
validation_targets = validation_csv[0]
validation_inputs = validation_csv[1]
correct_outputs = 0

# Validate the perceptron over the validation data set and record the accuracy achieved
for i in range(0, len(validation_targets)):
        t = validation_targets[i]
        in_values = validation_inputs[i]

        # Calculate the sum of the network inputs
        output = in_values[0] * weights[0] + in_values[1] * weights[1] + in_values[2] * weights[2]
        # Calculate the output of the network
        activation = activation_function(output)

        if activation == t:
            if verbose:
                print("Point (" + str(in_values[0]) + ", " + str(in_values[1]) + ") maps to " + str(t) + " - Correct")
            correct_outputs += 1
        else:
            if verbose:
                print("Point (" + str(in_values[0]) + ", " + str(in_values[1]) + ") maps to " + str(activation) + " - Incorrect")

if verbose:
    print("\nValidation complete" + line_separator)

percent_correct = correct_outputs / float(len(validation_targets))

if verbose:
    print("The classifier was able to predict " + str(percent_correct * 100) + "% of the validation set")
else:
    print(percent_correct)